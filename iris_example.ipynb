{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "data = pd.DataFrame(data=datasets.load_iris().data, columns=['seplen','sepwid','petlen','petwid'])\n",
    "data['target']=datasets.load_iris().target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('target').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[data.columns[:-1]],data['target'],test_size=0.2,random_state=23,stratify=data['target'])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scal = StandardScaler()\n",
    "x_train = scal.fit_transform(x_train)\n",
    "x_test = scal.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      1.00      1.00        10\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00        30\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      1.00      1.00        10\n",
      "          2       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       1.00      1.00      1.00        30\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C': [0.01,0.1,1,10]}\n",
    "clf = GridSearchCV(SVC(),parameters,cv=5)\n",
    "clf.fit(x_train,y_train)\n",
    "print(clf.best_params_)\n",
    "y_true,y_pred=y_test,clf.predict(x_test)\n",
    "print(classification_report(y_true,y_pred))\n",
    "accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22178881  0.2363588   0.52710905]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xc11e3c8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data[data.columns[0:3]],data[data.columns[3]],test_size=0.2,random_state=23)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(x_train,y_train)\n",
    "print(clf.coef_)\n",
    "y_true,y_pred = y_test,clf.predict(x_test)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[data.columns[:-1]],data['target'],test_size=0.2,random_state=23,stratify=data['target'])\n",
    "y_train = to_categorical(y_train, num_classes=len(set(data['target'])))\n",
    "y_test = to_categorical(y_test, num_classes=len(set(data['target'])))\n",
    "scal = StandardScaler()\n",
    "x_train = scal.fit_transform(x_train)\n",
    "x_test = scal.transform(x_test)\n",
    "          \n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='sigmoid', input_dim=x_train.shape[1]))\n",
    "model.add(Dense(len(set(data['target'])), activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7789 - acc: 0.5556\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.6954 - acc: 0.5556\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.6561 - acc: 0.5806\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.6313 - acc: 0.6667\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.6124 - acc: 0.6667\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.5982 - acc: 0.6667\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.5822 - acc: 0.6667\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.5725 - acc: 0.6667\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.5593 - acc: 0.6667\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.5499 - acc: 0.6694\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.5375 - acc: 0.6889\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.5275 - acc: 0.7083\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.5173 - acc: 0.7556\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.5072 - acc: 0.7667\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.4970 - acc: 0.7750\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.4870 - acc: 0.7833\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.4787 - acc: 0.7778\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.4678 - acc: 0.7944\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.4584 - acc: 0.8028\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.4496 - acc: 0.8000\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.4405 - acc: 0.8250\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.4320 - acc: 0.8389\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.4239 - acc: 0.8333\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.4160 - acc: 0.8306\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.4092 - acc: 0.8444\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.4015 - acc: 0.8500\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.3935 - acc: 0.8556\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.3867 - acc: 0.8472\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.3804 - acc: 0.8528\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.3743 - acc: 0.8528\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.3672 - acc: 0.8556\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.3605 - acc: 0.8500\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.3563 - acc: 0.8583\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.3492 - acc: 0.8639\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.3427 - acc: 0.8583\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.3393 - acc: 0.8611\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.3328 - acc: 0.8583\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.3273 - acc: 0.8667\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.3231 - acc: 0.8583\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.3168 - acc: 0.8778\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.3126 - acc: 0.8778\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.3082 - acc: 0.8806\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.3028 - acc: 0.8861\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2980 - acc: 0.8833\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2945 - acc: 0.8972\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2897 - acc: 0.8944\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2860 - acc: 0.8861\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2816 - acc: 0.8917\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2775 - acc: 0.9000\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2759 - acc: 0.8917\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2715 - acc: 0.8889\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2674 - acc: 0.9056\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2635 - acc: 0.8972\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2628 - acc: 0.9028\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2579 - acc: 0.9083\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2548 - acc: 0.9056\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2512 - acc: 0.9167\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2481 - acc: 0.9083\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2456 - acc: 0.9111\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2422 - acc: 0.9167\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2410 - acc: 0.9167\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2370 - acc: 0.9111\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2344 - acc: 0.9139\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2313 - acc: 0.9194\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2296 - acc: 0.9139\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2291 - acc: 0.9194\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2250 - acc: 0.9194\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2224 - acc: 0.9083\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2194 - acc: 0.9139\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2169 - acc: 0.9194\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2144 - acc: 0.9167\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2126 - acc: 0.9194\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2100 - acc: 0.9278\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2088 - acc: 0.9306\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2057 - acc: 0.9194\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2031 - acc: 0.9250\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2019 - acc: 0.9167\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1994 - acc: 0.9278\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1969 - acc: 0.9333\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1949 - acc: 0.9278\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1938 - acc: 0.9250\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1910 - acc: 0.9361\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1891 - acc: 0.9278\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 42us/step - loss: 0.1867 - acc: 0.9361\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1851 - acc: 0.9361\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1832 - acc: 0.9417\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1818 - acc: 0.9306\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1793 - acc: 0.9389\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1776 - acc: 0.9444\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1754 - acc: 0.9417\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1737 - acc: 0.9389\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1725 - acc: 0.9528\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.1701 - acc: 0.9444\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1691 - acc: 0.9583\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 25us/step - loss: 0.1665 - acc: 0.9417\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1648 - acc: 0.9528\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 25us/step - loss: 0.1655 - acc: 0.9472\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1617 - acc: 0.9472\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1603 - acc: 0.9556\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1584 - acc: 0.9528\n",
      "30/30 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)\n",
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.163055881857872, 0.9777777791023254]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
