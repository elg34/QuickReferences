{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('exp1_a.csv')\n",
    "\n",
    "# drop first two, irrelevant, columns\n",
    "data.drop(data.columns[0:2],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose rows at random for checking\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many missing values for the different columns?\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the rows that contain a missing value\n",
    "data.dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all columns with at least one missing value\n",
    "data.dropna(axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all NA's with 0\n",
    "data.fillna(0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputer fills na's (default: mean)\n",
    "from sklearn.preprocessing import Imputer\n",
    "my_imputer = Imputer()\n",
    "data_na=my_imputer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Initial plots & data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()\n",
    "#also: data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#data.boxplot()\n",
    "#data.hist()\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get frequencies in categorical vars\n",
    "data.groupby(['qua','dip']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting columns (Series)\n",
    "dat['ppt']\n",
    "dat[['ppt','qua']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if index is numeric\n",
    "dat.loc[0]==dat.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index as string\n",
    "dat.index = map(str,dat.index)\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if index is string dat.loc[0]==dat.iloc[0] would give a type error\n",
    "# if index is numeric\n",
    "dat.loc['0']==dat.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text='Any text!'\n",
    "# some substitutions\n",
    "re.sub(r'\\n.* PLACEHOLDER*\\n', ' ', text) # replace a line that includes the word PLACEHOLDER with a space\n",
    "re.sub(r'[A-Z]{2,}', ' ', text) # remove any sequence of capital letters larger than 1\n",
    "re.sub(r'\\n\\d+\\s.*\\n', ' ', text) # remove digits and space at the start of a line\n",
    "re.sub('\\[(.*?)\\]', '', text) # remove text within and including square brackets\n",
    "re.sub('[^A-Z]','',text) # delete all except capital letters\n",
    "\n",
    "# misc\n",
    "pd.Series(['test','abcde!','test12 :;;']).str.count(r'\\W') # count number of non word characters per entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub('[^A-Z]','','Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning - Categorical or continuous DV/Mixed IVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split & dummy coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randint\n",
    "y= [randint(0,1) for b in range(0,data.shape[0])] #data['dv'] for continuous\n",
    "X=data #data.drop('dv',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # stratify=y for balanced data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variables should be dummy coded for certain analyses\n",
    "pd.get_dummies(data['qua']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch (apply to various methods [Decision Trees, SVM, Logistic Regression, etc etc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# note: won't run on this example because I have a continuous y, just an example\n",
    "tuned_parameters = [{'C': [0.01,0.1,1, 10, 100, 1000]}]\n",
    "clf = GridSearchCV(LogisticRegression(class_weight='balanced'), tuned_parameters, cv=5, scoring='f1')\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print('Accuracy',accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy Classifier (for baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "dummy_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_classifier.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, dummy_classifier.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic statistical tests - continuous DV/categorical IVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets for different samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent measures\n",
    "nppt=100\n",
    "d = {'dv': np.random.normal(0, 1, nppt), \n",
    "     'subj': range(1,nppt+1),\n",
    "     'cond1': [1,2]*int(nppt/2),\n",
    "     'cond2': [1,2,3,4,5]*int(nppt/5)\n",
    "    }\n",
    "data = pd.DataFrame(data=d)\n",
    "data.groupby(['cond1','cond2']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated measures\n",
    "nppt_rm=10 # subj in rm design\n",
    "ntrials=20 # trials per cond in rm design\n",
    "ncond1=2 # levels of iv 1\n",
    "ncond2=3 # levels of IV 2\n",
    "drm = {'dv': np.random.normal(0, 1, nppt_rm*ntrials*ncond1*ncond2), \n",
    "     'subj': ((list(np.sort(list(range(1,nppt_rm+1))*ntrials))*ncond1)*ncond2),\n",
    "     'trial': ((list((list(range(1,ntrials+1))*nppt_rm))*ncond1)*ncond2),\n",
    "     'cond1': (list(np.sort((list(range(1,ncond1+1))*ntrials)*nppt_rm))*ncond2),\n",
    "     'cond2': list(np.sort(((list(range(1,ncond2+1))*ntrials)*nppt_rm)*ncond1))\n",
    "    }\n",
    "data_rm = pd.DataFrame(data=drm)\n",
    "# show counts in groups\n",
    "data_rm.groupby(['subj','cond1','cond2']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-test - independent samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(data['dv'][data['cond1']==1], data['dv'][data['cond1']==2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-test - dependent samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = data_rm.groupby(['subj','cond1']).mean().reset_index()\n",
    "stats.ttest_rel(rm['dv'][rm['cond1']==1], rm['dv'][rm['cond1']==2])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated p-value distributions for t-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy\n",
    "from scipy import stats\n",
    "F, p = stats.f_oneway(data['dv'][data['cond1']==1], data['dv'][data['cond1']==2])\n",
    "F,p\n",
    "\n",
    "# own function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Way RM ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own function (takes numpy array)\n",
    "def get_oneway_rm_anova(n,c,dat):\n",
    "    'One way RM ANOVA - n is n_subjects, c is number of levels of condition, dat is a numpy dataframe of shape (n,c)'\n",
    "    dfn=n-1 # degrees of freedom for number of subjects\n",
    "    dfm=c-1 # degrees of freedom for our condition\n",
    "    dftot=(len(dat.flatten())-1) # total degrees of freedom of array\n",
    "    dfw=n*dfm # degrees of freedom within\n",
    "    dfr=dfw-dfm # degrees of freedom residuals\n",
    "    mper=[np.mean(dat[i,:]) for i in range(n)] # ppt means, shape is (1,n)\n",
    "    mcond=[np.mean(dat[:,i]) for i in range(c)] # condition means, shape is (1,c)\n",
    "    mtot=np.mean(dat.flatten()) # total mean of all data points\n",
    "    sstot=sum([(i-mtot)**2 for i in dat.flatten()]) # SS of all data\n",
    "    ssw=np.sum([np.sum((dat[i,:]-mper[i])**2) for i in range(n)]) # SS within group (for each ppt how far group val from mean val for that ppt)\n",
    "    ssm=np.sum(n*[((mcond[i]-mtot)**2) for i in range(c)]) # SS conditions (for each condition, how far is the cond val from the total mean)\n",
    "    ssr=ssw-ssm # SS residuals (SS that remain from SSw after taking out the effect of our model)\n",
    "    msm=ssm/dfm # MS model\n",
    "    msr=ssr/dfr # MS residuals  c\n",
    "    f=msm/msr # F statistic\n",
    "    peta= ssm/ssw # get the proportion of total variance that is due to the model! (ssm+ssr)==ssw\n",
    "    geta= ssm/(ssw+(sstot-ssw)) # see bakeman 2005, for this case same as eta squared (not PARTIAL eta-squared)\n",
    "    return f,ssw,ssm,ssr,msm,msr,peta,geta\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-Way ANOVA/Two-Way RM ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would pipe the dataframe into R for this, probably as csvs rather than %R format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holm_bonferroni(pvals,alpha):\n",
    "    'Return corrected alpha level for input p-values.'\n",
    "    pvals=np.column_stack((pvals,np.array(range(len(pvals))))) # create a second column that gives the original rank\n",
    "    pvals=pvals[np.argsort(pvals[:,0])] # sort by size of pvalue\n",
    "    hb=np.empty([len(pvals),2]) # empty array for alpha levels\n",
    "    for i in range(len(pvals)):\n",
    "        hb[i,:]=[(alpha/(len(pvals)-i)), pvals[i,1]] # HB alpha = alpha/(n_pvals+1-rank) where i=rank-1, so +1 dropped\n",
    "    return hb[np.argsort(hb[:,1])][:,0] # sort to return original order and return only the adjusted alpha\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
